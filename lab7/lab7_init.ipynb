{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GjLwr7LHju9z"
   },
   "source": [
    "# MCMC Inference in Hierarchical Bayesian Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Y0Y7HX_yju91"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import mkl\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "np.random.seed(1234)\n",
    "mkl.set_num_threads(2)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams[\"figure.figsize\"] = [14, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usefull imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from tensorflow_probability import distributions as tfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr_plot_posterior_samples(ax, w_samples, data_x, data_y, data_ys, fill=False, title=None):\n",
    "    '''\n",
    "    Plot samples from a Bayesian linear regression.\n",
    "    \n",
    "    Args:\n",
    "        ax:        Axis for plotting.\n",
    "        w_samples: Samples from the posterior over regression parameters\n",
    "        data_x:    Explanatory variables.\n",
    "        data_y:    Responses.\n",
    "        data_ys:   Uncertainty in data_y.\n",
    "        fill:      Whether to fill area between the first and the last sample.\n",
    "        title:     Plot title.\n",
    "    '''\n",
    "    ax.errorbar(data_x[:, 0], data_y[:, 0], data_ys, None, marker=\"o\", ls='', capsize=5)\n",
    "    ax.set_xlabel('x', fontsize='xx-large')\n",
    "    ax.set_ylabel('y', fontsize='xx-large')\n",
    "\n",
    "    xmin, xmax = np.min(data_x[:, 0]), np.max(data_x[:, 0])\n",
    "    X = np.array([[xmin, 1], [xmax, 1]])\n",
    "    \n",
    "    Y = X @ tf.transpose(w_samples)\n",
    "    Y = tf.transpose(Y)\n",
    "    for y in Y:\n",
    "        ax.plot(X[:, 0], y, marker='', lw=1.0, alpha=0.5, color='r');\n",
    "    \n",
    "    if fill:\n",
    "        plt.fill_between(X[:, 0], Y[0, :], Y[-1, :], alpha=0.3)\n",
    "    \n",
    "    if title is not None:\n",
    "        ax.set_title(title, fontsize='x-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_posterior_dist(samples, labels, cri=95, round_ticks=False):\n",
    "    '''\n",
    "    Plot posterior distributions for parameters of a Bayesian model.\n",
    "    \n",
    "    Args:\n",
    "        samples:     a list of tensors with posterior samples (one tensor per parameter)\n",
    "        labels:      a list of parameter names (strings)\n",
    "        cri:         credible interval\n",
    "        round_ticks: whether to use integer ticks in distribution plots\n",
    "    '''\n",
    "    n_params = len(samples)\n",
    "    cri = (100 - cri) / 2\n",
    "    \n",
    "    f, axes = plt.subplots(1, n_params, figsize=(14, 7))\n",
    "    if n_params == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        g = sns.histplot(samples[i], kde=True, ax=ax)\n",
    "        ax.set_xlabel(labels[i], fontsize='xx-large')\n",
    "        ax.set_ylabel('Count', fontsize='xx-large')\n",
    "        \n",
    "        low  = np.percentile(samples[i], cri)\n",
    "        high = np.percentile(samples[i], 100-cri)\n",
    "        ax.axvline(x=low, linestyle='--')\n",
    "        ax.axvline(x=high, linestyle='--')\n",
    "        if round_ticks:\n",
    "            ax.xaxis.set_major_formatter(ticker.FormatStrFormatter(\"%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Linear Regression (again)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start our introduction to MCMC with a known simple model - Bayesian Linear Regression with unknown $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# D.W. Hogg et al. Data analysis recipes: Fitting a model to data, https://arxiv.org/abs/1008.4686, 2010\n",
    "hogg_data = np.array([[201, 592, 61],\n",
    "                      [244, 401, 25],\n",
    "                      [47, 583, 38],\n",
    "                      [287, 402, 15],\n",
    "                      [203, 495, 21],\n",
    "                      [58, 173, 15],\n",
    "                      [210, 479, 27],\n",
    "                      [202, 504, 14],\n",
    "                      [198, 510, 30],\n",
    "                      [158, 416, 16],\n",
    "                      [165, 393, 14],\n",
    "                      [201, 442, 25],\n",
    "                      [157, 317, 52],\n",
    "                      [131, 311, 16],\n",
    "                      [166, 400, 34],\n",
    "                      [160, 337, 31],\n",
    "                      [186, 423, 42],\n",
    "                      [125, 334, 26],\n",
    "                      [218, 533, 16],\n",
    "                      [146, 344, 22]], dtype=np.float32)\n",
    "\n",
    "\n",
    "hogg_x_npy, hogg_y_npy, hogg_ys_npy = hogg_data[:, 0], hogg_data[:, 1], hogg_data[:, 2]\n",
    "hogg_x_npy, hogg_y_npy = hogg_x_npy[:, None], hogg_y_npy[:, None]\n",
    "\n",
    "ones = np.ones((hogg_x_npy.shape[0], 1))\n",
    "hogg_x_npy = np.concatenate((hogg_x_npy, ones), axis=1)\n",
    "\n",
    "hogg_x = tf.constant(hogg_x_npy, dtype=tf.float32)\n",
    "hogg_y = tf.constant(hogg_y_npy, dtype=tf.float32)\n",
    "hogg_ys = tf.constant(hogg_ys_npy, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 7))\n",
    "plt.errorbar(hogg_x[:, 0], hogg_y[:, 0], hogg_ys, None, marker=\"o\", ls='', capsize=5)\n",
    "plt.xlabel('x', fontsize='xx-large')\n",
    "plt.ylabel('y', fontsize='xx-large');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets recall our model from the previous lab:\n",
    "\n",
    "$$\\large\n",
    "\\begin{aligned}\n",
    "  \\sigma & \\sim \\mathrm{HalfCauchy}\\left(\\mathrm{loc} = 0,\\ \\mathrm{scale} = 10\\right) \\\\\n",
    "  \\mathbf{w} & \\sim N \\left(\\boldsymbol \\mu_0, \\mathbf{\\Sigma}_0 \\right) \\\\\n",
    "  y \\mid \\mathbf{x}, \\mathbf{w}, \\mathbf{\\sigma} & \\sim\n",
    "    N \\left(\\mathbf{w}^\\mathsf{T}\\mathbf{x}, \\sigma^2 \\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We will now infer parameters of this model with Markov Chain Monte Carlo.\n",
    "\n",
    "---\n",
    "\n",
    "As usuall, we will begin by defining prior distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_mean, y_var = np.mean(hogg_y[:, 0]), np.var(hogg_y[:, 0])\n",
    "\n",
    "mu_0_npy    = np.array([0, y_mean])\n",
    "Sigma_0_npy = np.array([[1, 0],\n",
    "                        [0, y_var]])\n",
    "\n",
    "mu_0, Sigma_0 = tf.constant(mu_0_npy, dtype=tf.float32), tf.constant(Sigma_0_npy, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior_w     = tfd.MultivariateNormalFullCovariance(tf.squeeze(mu_0), Sigma_0)\n",
    "prior_sigma = tfd.HalfCauchy(loc=0, scale=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior in our model has the following form:\n",
    "\n",
    "$$\\large\n",
    "p\\left(\\mathbf{w}, \\sigma \\mid D\\right) =  \\frac{1}{Z} p\\left(D \\mid \\mathbf{w}, \\sigma\\right)\n",
    "                                                       p\\left(\\mathbf{w}\\right)\n",
    "                                                       p\\left(\\sigma\\right)\n",
    "$$\n",
    "\n",
    "Thereâ€™s is no way we could calculate the normalization constant $Z$. But we know from the lecture that MCMC will work as well with unnormalized posterior. Note that this unnormalized posterior can be seen as the joint probability density of observations and parameters:\n",
    "\n",
    "$$\\large\n",
    "p\\left(D, \\mathbf{w}, \\sigma\\right) =  p\\left(D \\mid \\mathbf{w}, \\sigma\\right)\n",
    "                                       p\\left(\\mathbf{w}\\right)\n",
    "                                       p\\left(\\sigma\\right)\n",
    "$$\n",
    "\n",
    "Actual MCMC implementations doesn't work with this joint density directly. They instead expect a logarithm of the joint density - a so called log-joint:\n",
    "\n",
    "$$\\large\n",
    "\\log p\\left(D, \\mathbf{w}, \\sigma\\right) =  \\log p\\left(D \\mid \\mathbf{w}, \\sigma\\right) +\n",
    "                                            \\log p\\left(\\mathbf{w}\\right) +\n",
    "                                            \\log p\\left(\\sigma\\right)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Let's implement the log-joint density for the Bayesian Linear Regression model. For reasons that will be clear shortly we will split regression slope and intercept into two separate arguments.\n",
    "\n",
    "Complete the implementation of `lr_log_joint` function following comments in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr_log_joint(w0, w1, sigma):\n",
    "    '''\n",
    "    Calculate log-joint density in Bayesian Linear Regression model.\n",
    "    \n",
    "    Args:\n",
    "        w0: linear regression slope\n",
    "        w1: linear regression intercept\n",
    "        sigma: standard deviation of measurement errors\n",
    "               (uncertainty of observations)\n",
    "               \n",
    "    Returns:\n",
    "        Logarithm of the joint density of observations (hogg_x, hogg_y) and\n",
    "        parameters (w, sigma).\n",
    "    '''\n",
    "    \n",
    "    # Following our convention, we keep regression parameters in a single vector. \n",
    "    # So we begin by stacking w0 and w1 tensors.\n",
    "    w = tf.stack([w0, w1])\n",
    "    \n",
    "    # Now we can calculate expected value in the linear regression fit.\n",
    "    Z = hogg_x @ tf.reshape(w, [-1, 1])\n",
    "    \n",
    "    # We now have all that's needed to calculate the log-likelihood.\n",
    "    raise Exception('Create a batch of likelihood distributions. Then calculate '\n",
    "                    'log-likelihood and store the result in `ll` variable.')\n",
    "    \n",
    "    #ll = ???\n",
    "    \n",
    "    # And finally we can calculate log-joint\n",
    "    raise Exception('Calculate log-joint density and store the result in `logp` variable.')\n",
    "    \n",
    "    #logp = ??\n",
    "    \n",
    "    return logp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC machinery\n",
    "\n",
    "We are now ready to setup our MCMC infrastructure. We will use Hamiltonian Monte Carlo (HMC), but you can also easily switch to NUTS.\n",
    "\n",
    "---\n",
    "\n",
    "First we define the transition kernel. All MCMC kernels take a handle to the log-probability function as their argument. HMC also requires a step-size and number of steps to take in each proposal.\n",
    "\n",
    "Now, note something important - we provide a list of three different step sizes! This is no mistake - these step sizes correspond to the parameters listed as arguments in the log-joint function. So:\n",
    "- Regression slope has a step size of 0.1 - seems reasonable as we expect regression slope to be a small number around 0.\n",
    "- Regression intercept has a step size of 10.0 - note that intercept seems to vary on the scale of hundreds,\n",
    "- Measurement error ($\\sigma$) has a step size of 1.0 - we expect it to be somewhere between a few dozens to perhaps a hundred.\n",
    "\n",
    "It should be clear now why we split $\\mathbf{w}$ into two arguments in `lr_log_joint` - we want separate step size of regression slope and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_hmc_kernel = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "    target_log_prob_fn=lr_log_joint,\n",
    "    step_size=[0.1, 10.0, 1.0],\n",
    "    num_leapfrog_steps=2)\n",
    "\n",
    "#lr_nuts_kernel = tfp.mcmc.NoUTurnSampler(\n",
    "#    target_log_prob_fn=lr_log_joint,\n",
    "#    step_size=[0.1, 10.0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define a function that will run our Markov Chain. This function simply wraps `tfp.mcmc.sample_chain` from TensorFlow probability.\n",
    "\n",
    "There is a good reason why we wrap `tfp.mcmc.sample_chain` - it's the `@tf.function` decorator. It tells TensorFlow to treat the whole `run_chain` function as a computation graph, rather than simple eagerly evaluated function. So when we execute `run_chain` TensorFlow will construct a computation graph for the whole MCMC procedure, optimize that graph and then execute it. Graph optimization will save us a lot of computing time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_chain(kernel, initial_state, num_results=1000, num_burnin_steps=1000):\n",
    "    '''\n",
    "    Sample Markov chain.\n",
    "    \n",
    "    Args:\n",
    "        kernel:           transition kernel\n",
    "        initial_state:    initial state of the chain\n",
    "        num_results:      number of samples to return\n",
    "        num_burnin_steps: number of initial steps to throw away (burn-in period)\n",
    "        \n",
    "    Returns:\n",
    "        Samples from the chain and trace of kernel executions.\n",
    "    '''\n",
    "    return tfp.mcmc.sample_chain(\n",
    "        num_results=num_results,\n",
    "        num_burnin_steps=num_burnin_steps,\n",
    "        current_state=initial_state,\n",
    "        kernel=kernel,\n",
    "        trace_fn=lambda current_state, kernel_results: kernel_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next in line is the initial state of the chain. We will use $\\boldsymbol \\mu_0$ for initial $\\mathbf{w}$ and a reasonable guess for $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_initial_state = [mu_0[0], mu_0[1], 25.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can run the chain :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_samples, lr_kernel_results = run_chain(lr_hmc_kernel,\n",
    "                                          lr_initial_state,\n",
    "                                          num_results=1000,\n",
    "                                          num_burnin_steps=1000)\n",
    "\n",
    "print(\"Acceptance rate: \", lr_kernel_results.is_accepted.numpy().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if our samples agree with Importance Sampling results (see previous lab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma_samples = lr_samples[2].numpy()\n",
    "\n",
    "w_samples = tf.stack([lr_samples[0], lr_samples[1]], axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_mean, sigma_std = np.mean(sigma_samples), np.std(sigma_samples)\n",
    "print(f'sigma: {sigma_mean:.4} +- {sigma_std:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_mean, w_std = np.mean(w_samples, axis=0), np.std(w_samples, axis=0)\n",
    "\n",
    "w_span = np.array([w_mean + w_std,\n",
    "                   w_mean - w_std])\n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "lr_plot_posterior_samples(plt.gca(), w_span, hogg_x, hogg_y, sigma_mean, fill=True, title='Posterior width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change point model\n",
    "\n",
    "Now let's try a more interesting Bayesian analysis. This example is derived from the change-point model in https://docs.pymc.io/notebooks/getting_started.html\n",
    "\n",
    "---\n",
    "\n",
    "We will try to get some insight into the number of mining disasters in the United Kingdom that happened between 1851 and 1962. Let's load and plot this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coal mining disasters in the UK from 1851 to 1962\n",
    "disaster_count = np.array([ 4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6,\n",
    "                            3, 3, 5, 4, 5, 3, 1, 4, 4, 1, 5, 5, 3, 4, 2, 5,\n",
    "                            2, 2, 3, 4, 2, 1, 3, 2, 2, 1, 1, 1, 1, 3, 0, 0,\n",
    "                            1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1,\n",
    "                            0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2,\n",
    "                            3, 3, 1, 1, 2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 1, 4,\n",
    "                            0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1],\n",
    "                            dtype=np.float32)\n",
    "\n",
    "years = np.arange(1851, 1962, dtype=np.int32)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "plt.plot(years, disaster_count, 'r+', markersize=10);\n",
    "plt.xlabel('Year', fontsize='xx-large')\n",
    "plt.ylabel('Number of disasters', fontsize='xx-large');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our question is: can we pinpoint any point changes in this time series? Perhaps a year after which the number of disasters decreased or increased? What model could we use to answer such a question?\n",
    "\n",
    "---\n",
    "\n",
    "First, lets think about the likelihood - what probability distribution could be seen as generating this data? Each data point is basically a count of events (disasters in a year) - such observations are often well modelled by Poisson distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 20, 1.)\n",
    "\n",
    "p1_prob = tfd.Poisson(rate=1).prob(x)\n",
    "p4_prob = tfd.Poisson(rate=4).prob(x)\n",
    "p10_prob = tfd.Poisson(rate=10).prob(x)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "plt.plot(x, p1_prob, marker='o', ls='--', lw=1.0, color='r', label=r'$\\lambda=1$');\n",
    "plt.plot(x, p4_prob, marker='o', ls='--', lw=1.0, color='g', label=r'$\\lambda=4$');\n",
    "plt.plot(x, p10_prob, marker='o', ls='--', lw=1.0, color='b', label=r'$\\lambda=10$')\n",
    "plt.legend(prop={'size': 18});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we could write down the likelihood as:\n",
    "\n",
    "$$\\large\n",
    "\\mathrm{count} \\sim \\textrm{Pos}(\\lambda)\n",
    "$$\n",
    "\n",
    "where $\\lambda$ is the mean rate of disasters.\n",
    "\n",
    "However, our hypothesis is that there is perhaps a point in this time series where expected disaster count changes. Let it be year $T$. We would then expect one rate of disasters before $T$ - say $\\lambda_1$ - and a different rate after $T$ - say $\\lambda_2$. Likelihood under such scenario would be:\n",
    "\n",
    "$$\\large\n",
    "\\begin{aligned}\n",
    "  \\mathrm{count} \\mid \\textrm{year} < T    & \\sim \\textrm{Pos}(\\lambda_1) \\\\\n",
    "  \\mathrm{count} \\mid \\textrm{year} \\geq T & \\sim \\textrm{Pos}(\\lambda_2)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Now the priors. We have no idea when the disaster rate changed - if it changed at all. Obviously, uniform prior over all years is a sensible choice:\n",
    "\n",
    "$$\\large\n",
    "T \\sim \\mathrm{U}(1851, 1962)\n",
    "$$\n",
    "\n",
    "What about the rates? We observe between 0 and 6 disasters annually. So we expect the mean rate to be a small positive number - likely less than 3. An exponential distribution is a good choice for small positive numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 4, 0.05)\n",
    "\n",
    "e1_prob = tfd.Exponential(rate=1).prob(x)\n",
    "e2_prob = tfd.Exponential(rate=2).prob(x)\n",
    "e3_prob = tfd.Exponential(rate=3).prob(x)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "plt.plot(x, e1_prob, ls='-', lw=1.0, color='r', label=r'$\\lambda=1$');\n",
    "plt.plot(x, e2_prob, ls='-', lw=1.0, color='g', label=r'$\\lambda=2$');\n",
    "plt.plot(x, e3_prob, ls='-', lw=1.0, color='b', label=r'$\\lambda=3$')\n",
    "plt.legend(prop={'size': 18});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems an exponential distribution with rate 1 should be a good prior for mean disaster rate. That means our complete model is:\n",
    "\n",
    "$$\\large\n",
    "\\begin{aligned}\n",
    "  \\lambda_1, \\lambda_2 & \\sim \\mathrm{Exp}(1) \\\\\n",
    "  T & \\sim \\mathrm{U}(1851, 1962) \\\\\n",
    "  \\mathrm{count} \\mid \\textrm{year} < T    & \\sim \\textrm{Pos}(\\lambda_1) \\\\\n",
    "  \\mathrm{count} \\mid \\textrm{year} \\geq T & \\sim \\textrm{Pos}(\\lambda_2)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Let's implement this model in TensorFlow probability and see if there is any evidence in the data for point change in disaster rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Priors\n",
    "\n",
    "prior_T        = tfd.Uniform(low=1851, high=1962)\n",
    "prior_lambda_1 = tfd.Exponential(rate=1.0)\n",
    "prior_lambda_2 = tfd.Exponential(rate=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the `point_change_log_joint` function which calculates log-joint density in the Change Point model. You will likely want to use:\n",
    "- `tf.gather` - this function can pick elements from a list (or a tensor) according to the given indices,\n",
    "- `tf.range(1851, 1962, dtype=tf.float32)` - a simple way to construct a tensor with list of years,\n",
    "- `tf.cast(X, tf.int32)` - this will cast tensor `X` to integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def point_change_log_joint(lambda_1, lambda_2, T):\n",
    "    '''\n",
    "    Calculate log-joint density in Change Point model.\n",
    "    \n",
    "    Args:\n",
    "        lambda_1: rate before the change\n",
    "        lambda_1: rate after the change\n",
    "        T:        change point\n",
    "               \n",
    "    Returns:\n",
    "        Logarithm of the joint density of observations (disaster_count) and\n",
    "        parameters (lambda_1, lambda_2, T).\n",
    "    '''\n",
    "    \n",
    "    raise Exception('Unimplemented.')\n",
    "    \n",
    "    #logp = ??\n",
    "    \n",
    "    return logp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use an uninformative guess for the initial state:\n",
    "- mean disaster rate is 1 (before and after the supposed change in disaster rate),\n",
    "- the change in disaster year happened in the middle of the interval for which we have data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "point_change_initial_state = [1.0, 1.0, (1851 + 1962)/2]\n",
    "\n",
    "\n",
    "point_change_hmc_kernel = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "    target_log_prob_fn=point_change_log_joint,\n",
    "    step_size=[0.05, 0.05, 1.0],\n",
    "    num_leapfrog_steps=2)\n",
    "\n",
    "#point_change_nuts_kernel = tfp.mcmc.NoUTurnSampler(\n",
    "#    target_log_prob_fn=point_change_log_joint,\n",
    "#    step_size=[0.05, 0.05, 1.0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can draw samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_change_samples, point_change_kernel_results = run_chain(point_change_hmc_kernel,\n",
    "                                                              point_change_initial_state,\n",
    "                                                              num_results=2000,\n",
    "                                                              num_burnin_steps=1000)\n",
    "\n",
    "print(\"Acceptance rate: \", point_change_kernel_results.is_accepted.numpy().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the results. We will plot posterior disribution (histogram) for each parameter in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_posterior_dist(point_change_samples[:2], [r'$\\lambda_1$', r'$\\lambda_2$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_posterior_dist([point_change_samples[2]], ['Change point'], round_ticks=True)"
   ]
  },
  {
   "attachments": {
    "interval_change.svg": {
     "image/svg+xml": [
      "<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" width="529px" height="197px" viewBox="-0.5 -0.5 529 197" content="&lt;mxfile host=&quot;app.diagrams.net&quot; modified=&quot;2020-05-28T01:06:48.570Z&quot; agent=&quot;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36&quot; version=&quot;13.1.0&quot; etag=&quot;-PuQr5-lfWzyNvjBf2-2&quot; type=&quot;device&quot;&gt;&lt;diagram id=&quot;2ItrgnlTKXnlqwUELf1l&quot;&gt;5Vhdb5swFP01PCbCmM/HNm23PUyq1ElbH63gJtYIZsZpyH79rmMbMNA0rdKq1XhI8LnXX+eci0k8vNg0XwSp1t95Tgsv8PPGw1deECQBhk8F7DUQ+oEGVoLlGkIdcMf+UgP6Bt2ynNZOouS8kKxywSUvS7qUDkaE4Ds37YEX7qwVWdERcLckxRj9yXK51mgaJB3+lbLV2s6M4kxHNsQmm53Ua5LzXQ/C1x5eCM6lvts0C1oo7iwvut/NE9F2YYKW8pQOhvdHUmzN3sy65N5uVvBtmVOV73v4crdmkt5VZKmiO1AXsLXcFNBCcGuGo0LS5skloXajYBDKN1SKPaTYDrHhxpgDYdPedVSHicHWfZojAxIj76odu2MAbgwJ04TgCULiAma4fOCw/j4z8Z8tt4FZfTDpBSQEYdV0Qbhbqe97SkRth4JF6NF0bEQ5kCddXmsp+G+64AUXgJS8pGpiVhQDiBRsVUJzCWRTwC+VFAyce2ECG5bnappJIV2pz6AljlwtgzQZazkhZXAGJcM3UvK6qeCZAizB84vVpFY8B74gkn4ueQWXRDKues2yM+kdDko3G5cuSif0xmfQO3r+UbbcisfD/hXntMwv1FnQsdsTBII3TE11oAp2L/a/2hA07lVknkS2fdX0U6/2ttUwqfrN/LnvhwbQfRFCpt31VY1+11sqGPCglD5grk08oA2uLGu1o/ng3Kr5Viyp86iXRKyodKAT9O0JGE3oZzFBC/DUo7uIKVHNDLecHUqxsWUfuP6JB77Q+zG9+sfaYKBoYMTWmHYgzcJoIDAE2ffSKpVQH1lwMjB86B9dFwg2WBceWFyvoDN8q8FJNRA/XwNHbf+EjT6OQZJ07vcu5LKZpK+zy/FhUZCdZJ5X6JW80Rn143MdRWc4eYIoHbxpxO/2ppG+qOp4Rcsh5UTIQfiAOUeQeyDZX0XIt8l94MPXMU7nWf9yCy5JXlfHGD0z0PkqNztT5Wq1/IKVdGaJVlH15hSNC/ubKjaYtFXqf6tzjAavCGE2qnPkH3HuCwodmt0vce2R7u8MfP0P&lt;/diagram&gt;&lt;/mxfile&gt;" style="background-color: rgb(255, 255, 255);"><defs/><g><rect x="58" y="15" width="470" height="150" fill="#ffffff" stroke="#000000" pointer-events="all"/><rect x="248" y="172" width="40" height="20" fill="none" stroke="none" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 38px; height: 1px; padding-top: 182px; margin-left: 249px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; "><font style="font-size: 24px">Years</font></div></div></div></foreignObject><text x="268" y="186" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">Years</text></switch></g><rect x="-62" y="75" width="180" height="30" fill="none" stroke="none" transform="rotate(-90,28,90)" pointer-events="all"/><g transform="translate(-0.5 -0.5)rotate(-90 28 90)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 178px; height: 1px; padding-top: 90px; margin-left: -61px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; "><font style="font-size: 24px">Expected disaster rate</font></div></div></div></foreignObject><text x="28" y="94" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">Expected disaster rate</text></switch></g><path d="M 56.12 31.65 Q 168 25 183 76.5 Q 198 128 528 127.5" fill="none" stroke="#000099" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 176 163 L 176 14" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><rect x="156" y="171" width="40" height="20" fill="none" stroke="none" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 38px; height: 1px; padding-top: 181px; margin-left: 157px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; "><font style="font-size: 24px">T</font></div></div></div></foreignObject><text x="176" y="185" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">T</text></switch></g><path d="M 139.24 62 L 214.76 62" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 149.12 56.5 L 138.12 62 L 149.12 67.5" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><path d="M 204.88 67.5 L 215.88 62 L 204.88 56.5" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><rect x="210" y="34" width="100" height="50" fill="none" stroke="none" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 98px; height: 1px; padding-top: 59px; margin-left: 211px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 12px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; "><font style="font-size: 24px ; line-height: 90%">Interval width</font></div></div></div></foreignObject><text x="260" y="63" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">Interval width</text></switch></g></g><switch><g requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"/><a transform="translate(0,-5)" xlink:href="https://desk.draw.io/support/solutions/articles/16000042487" target="_blank"><text text-anchor="middle" font-size="10px" x="50%" y="100%">Viewer does not support full SVG 1.1</text></a></switch></svg>"
     ]
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interval Change Model\n",
    "\n",
    "The problem with the model described above is that it assumes a point-wise change. Changes in mining safety may as well take several years.\n",
    "\n",
    "Your task now is to extend the Change Point model to a model of an interval change. In other words, we expect a model that assumes a change like this:\n",
    "\n",
    "![interval_change.svg](attachment:interval_change.svg)\n",
    "\n",
    "Your model should have following parameters:\n",
    "\n",
    "- $\\lambda_1$, $\\lambda_2$ - expected disaster rates (respectively, before and after the change),\n",
    "- $T$ - center of the change interval,\n",
    "- $L$ - width of the change interval.\n",
    "\n",
    "---\n",
    "\n",
    "**Write down your model here (preferably with formal notation). Also, include a short justification for your model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define a prior for $L$. Other parameter can use priors from the previous model. Finally, implement the `interval_change_log_joint` function, which should calculate log-joint density in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raise Exception('Define a prior distribution for the width of the change interval.')\n",
    "\n",
    "#prior_L = ???\n",
    "\n",
    "def interval_change_log_joint(lambda_1, lambda_2, T, L):\n",
    "    '''\n",
    "    Calculate log-joint density in Change Interval model.\n",
    "    \n",
    "    Args:\n",
    "        lambda_1: rate before the change\n",
    "        lambda_1: rate after the change\n",
    "        T:        center of the change interval\n",
    "        L:        width of the change interval\n",
    "        \n",
    "    Returns:\n",
    "        Logarithm of the joint density of observations (disaster_count) and\n",
    "        parameters (lambda_1, lambda_2, T, L).\n",
    "    '''\n",
    "    \n",
    "    raise Exception('Unimplemented.')\n",
    "    \n",
    "    #logp = ??\n",
    "    \n",
    "    return logp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's infer parameter of your model and see how it performs. Again, we start from an uninformative guess for the initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interval_change_initial_state = [1.0, 1.0, (1851 + 1962)/2, 5.0]\n",
    "\n",
    "\n",
    "interval_change_hmc_kernel = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "    target_log_prob_fn=interval_change_log_joint,\n",
    "    step_size=[0.05, 0.05, 1.0, 1.0],\n",
    "    num_leapfrog_steps=2)\n",
    "\n",
    "#interval_change_nuts_kernel = tfp.mcmc.NoUTurnSampler(\n",
    "#    target_log_prob_fn=interval_change_log_joint,\n",
    "#    step_size=[0.05, 0.05, 1.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_change_samples, interval_change_kernel_results = run_chain(interval_change_hmc_kernel,\n",
    "                                                                    interval_change_initial_state,\n",
    "                                                                    num_results=1000,\n",
    "                                                                    num_burnin_steps=1000)\n",
    "\n",
    "print(\"Acceptance rate: \", interval_change_kernel_results.is_accepted.numpy().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the posterior distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_posterior_dist(interval_change_samples[:2], [r'$\\lambda_1$', r'$\\lambda_2$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_posterior_dist(interval_change_samples[2:],\n",
    "                    ['Change interval center', 'Change interval width'],\n",
    "                    round_ticks=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Random.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
